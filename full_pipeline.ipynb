{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c49d93ef",
   "metadata": {},
   "source": [
    "# Training Pipeline Notebook\n",
    "\n",
    "This notebook bundles configuration, dataset utilities, model definitions, training loop, and evaluation into a single self‑contained workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6510c123",
   "metadata": {},
   "source": [
    "## 1. Configuration & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81465c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd                              \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader \n",
    "from torch.amp import autocast\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from sklearn.metrics import average_precision_score, precision_recall_fscore_support, f1_score\n",
    "from data_utils import DataPartition\n",
    "import warnings # Suppress warnings that currently do not affect execution\n",
    "warnings.filterwarnings(\"ignore\", message=\"torch.meshgrid: in an upcoming release\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Cannot set number of intraop threads after parallel work has started or after set_num_threads call\")\n",
    "\n",
    "# Hyperparameters\n",
    "DEBUG_MODE = True # Uses sample of 200 \n",
    "USE_GPU = True\n",
    "MODEL_NAME = \"swinv2_base_window12to24_192to384\"\n",
    "IMG_WIDTH = 384\n",
    "N_EPOCHS = 2          \n",
    "BATCH_SIZE = 2\n",
    "LEARNING_RATE = 1e-5\n",
    "PATIENCE = 8\n",
    "DROPOUT_RATE = 0.5\n",
    "SCHEDULER_T0 = 6\n",
    "SCHEDULER_T_MULT = 1\n",
    "MIN_LR = 1e-6\n",
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "RANDOM_SEED = 42\n",
    "THRESHOLD_MODE = 'per_label'  # choices: 'per_label', 'global'\n",
    "GLOBAL_THRESHOLD = 0.5\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Device setup\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    pin_memory = True\n",
    "    amp_dtype = torch.bfloat16\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    pin_memory = False\n",
    "    amp_dtype = torch.float32\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06279773",
   "metadata": {},
   "source": [
    "## 2. Dataset Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee06424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON Parsers and Helpers\n",
    "def get_confidence_score(response_str):\n",
    "    try:\n",
    "        return int(response_str.split()[0])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_classifications(record, threshold):\n",
    "    labels_positive = {}\n",
    "    for project in record.get(\"projects\", {}).values():\n",
    "        for label in project.get(\"labels\", []):\n",
    "            for classification in label.get(\"annotations\", {}).get(\"classifications\", []):\n",
    "                name = classification.get(\"name\")\n",
    "                positive = False\n",
    "                for answer in classification.get(\"checklist_answers\", []):\n",
    "                    score = get_confidence_score(answer.get(\"name\", \"\"))\n",
    "                    if score is not None and score <= threshold:\n",
    "                        positive = True\n",
    "                        break\n",
    "                val = classification.get(\"value\", \"\")\n",
    "                if not positive and val and val[0].isdigit() and int(val[0]) <= threshold:\n",
    "                    positive = True\n",
    "                if name:\n",
    "                    labels_positive[name] = int(labels_positive.get(name, 0) or positive)\n",
    "    return labels_positive\n",
    "\n",
    "def get_base_filename(fn):\n",
    "    for suf in [\"_left.jpg\", \"_right.jpg\"]:\n",
    "        if fn.endswith(suf):\n",
    "            return fn[:-len(suf)]\n",
    "    return os.path.splitext(fn)[0]\n",
    "\n",
    "def create_ndjson_image_path_mapping(base_dir):\n",
    "    pattern = os.path.join(base_dir, \"*\", \"*\", \"split_jpg\", \"*.jpg\")\n",
    "    return {os.path.basename(p): p for p in glob.glob(pattern, recursive=True)}\n",
    "\n",
    "# CSV Parsers and Helpers\n",
    "def load_csv_to_df(filepath, img_dir):\n",
    "    df = pd.read_csv(filepath) \n",
    "    df[\"group_id\"] = [os.path.splitext(filename)[0] for filename in df[\"Filenames\"]] # Add 'group_id' by removing the file extension.\n",
    "    df[\"image_path\"] = [os.path.join(img_dir, filename) for filename in df[\"Filenames\"]] # Add 'image_path' by joining the img_dir with the filename.\n",
    "    return df   \n",
    "\n",
    "def group_stratified_split(df, label_columns, group_col, split_ratio, seed):\n",
    "    unique_groups_array = df[group_col].unique()\n",
    "    aggregated_labels = [] \n",
    "    for group in unique_groups_array:\n",
    "        group_df = df[df[group_col] == group] # Extract the subset of rows for this group.\n",
    "        agg_labels = group_df[label_columns].max()  # Use max() across rows for each label column to simulate a logical OR combining the labels per group\n",
    "        aggregated_labels.append(agg_labels)\n",
    "    aggregated_labels_array = np.array(aggregated_labels)\n",
    "    # Initialize the multilabel stratified shuffle split with the desired test size and random seed.\n",
    "    splitter = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=split_ratio, random_state=seed)\n",
    "    # Use the splitter to get indices for train and test groups based on the aggregated labels.\n",
    "    for first_split_idx, second_split_idx in splitter.split(unique_groups_array.reshape(-1, 1), aggregated_labels_array):\n",
    "        first_groups = unique_groups_array[first_split_idx]\n",
    "        second_groups = unique_groups_array[second_split_idx]\n",
    "    # Create the final DataFrame splits by selecting rows that belong to each group split.\n",
    "    df_split_1 = df[df[group_col].isin(first_groups)].reset_index(drop=True)\n",
    "    df_split_2 = df[df[group_col].isin(second_groups)].reset_index(drop=True)\n",
    "    return df_split_1, df_split_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139dcd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST move DataPartition into a separate file (data_utils.py)\n",
    "# in order to run the notebook version with num_workers > 0 for GPU training\n",
    "\n",
    "# class DataPartition(Dataset):\n",
    "#     def __init__(self, df, label_columns, transform=None):\n",
    "#         self.label_columns = label_columns\n",
    "#         self.transform = transform\n",
    "#         self.img_paths = df[\"image_path\"].tolist() # List of image paths\n",
    "#         self.labels = df[label_columns].to_numpy(dtype=np.float32) # 2-D Array of of shape (N_samples, N_labels)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.img_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path  = self.img_paths[idx]\n",
    "#         img = Image.open(img_path).convert(\"RGB\") # Retrieve image\n",
    "#         if self.transform:                        # Apply transformations to image\n",
    "#             img = self.transform(img)\n",
    "#         label_vector = torch.from_numpy(self.labels[idx]) # Retrieve label vector for the given sample\n",
    "#         return img, label_vector\n",
    "        \n",
    "# Data Augmentation (Transforms)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_WIDTH, IMG_WIDTH)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_WIDTH, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f87a7",
   "metadata": {},
   "source": [
    "## 3. Model & Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPool2d(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.query = nn.Parameter(torch.randn(1, in_channels)) # Learnable query vector of shape [1, C]\n",
    "        self.to_key = nn.Conv2d(in_channels, in_channels, kernel_size=1, bias=False) # 1×1 convs for keys & values\n",
    "        self.to_value = nn.Conv2d(in_channels, in_channels, kernel_size=1, bias=False)\n",
    "        self.scale = in_channels ** -0.5 # Scaling factor for dot‑product attention\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape # x: [B, C, H, W]\n",
    "        # Produce raw keys & values: [B, C, H, W] → [B, C, H*W] then reshape to [B, C, N] and permute to [B, N, C]\n",
    "        key = self.to_key(x).reshape(B, C, -1).permute(0, 2, 1) # Keys and values: [B, N, C]s\n",
    "        value = self.to_value(x).reshape(B, C, -1).permute(0, 2, 1)\n",
    "        query = self.query.expand(B, -1).unsqueeze(1) # Expand single query to one per batch: [1, C] → [B, 1, C]\n",
    "        attn = torch.softmax(torch.matmul(query, key.transpose(-1, -2)) * self.scale, dim=-1) # Compute scaled dot‑product attention: [B, 1, N]\n",
    "        output = torch.matmul(attn, value) # Weighted sum of values: [B, 1, C]\n",
    "        return output.squeeze(1) # Squeeze to [B, C]\n",
    "\n",
    "class SwinTransformerMultiLabel(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=True):\n",
    "        super().__init__()\n",
    "        # 1) Model backbone without pooling/head\n",
    "        self.model = timm.create_model(MODEL_NAME, pretrained=pretrained, num_classes=0, global_pool=\"\")\n",
    "        # 2) Attention pool + dropout + classifier head\n",
    "        in_features = self.model.num_features\n",
    "        self.attn_pool = AttentionPool2d(in_features)\n",
    "        self.dropout = nn.Dropout(DROPOUT_RATE)\n",
    "        self.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        feat_map = self.model.forward_features(imgs) # Backbone -> feature map [B, H', W', C], downsampled\n",
    "        feat_map = feat_map.permute(0, 3, 1, 2) # Permute to [B, C, H', W']\n",
    "        pooled = self.attn_pool(feat_map) # Attention pooling -> [B, C]\n",
    "        # Head\n",
    "        features = self.dropout(pooled)\n",
    "        logits = self.fc(features)  # Pass through a linear fc layer to get one score per class for each example in the batch: [B, num_classes]\n",
    "        return logits\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self, model, transform, device, labels, thresholds):\n",
    "        self.model = model.to(device).eval()\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "        self.labels = labels \n",
    "        self.thresholds = thresholds\n",
    "\n",
    "    def predict(self, img):\n",
    "        tensor = self.transform(img).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(tensor)\n",
    "            probabilities  = torch.sigmoid(logits).cpu().numpy()[0]  # [K]\n",
    "        return (probabilities >= self.thresholds).astype(int)\n",
    "\n",
    "    def save(self, filename):\n",
    "        torch.save(self.model.state_dict(), filename + \".pt\") # Save model weights\n",
    "        thresholds_list = self.thresholds.tolist() # Gather thresholds into a JSON‑safe list\n",
    "        config = { # Build and write the JSON metadata config\n",
    "            \"thresholds\": thresholds_list,\n",
    "            \"labels\": self.labels\n",
    "        }\n",
    "        with open(filename + \".json\", \"w\") as file:\n",
    "            json.dump(config, file, indent=2)\n",
    "        print(f\"Model Weights saved as {filename}.pt | Classifier Metadata saved as {filename}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab75cd4",
   "metadata": {},
   "source": [
    "## 4. Training Monitor & Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983df83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingMonitor:\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_mAPs = []\n",
    "        self.start=time.time()\n",
    "    def report_epoch(self, train_loss, val_loss, val_map):\n",
    "        self.train_losses.append(train_loss)\n",
    "        self.val_losses.append(val_loss)\n",
    "        self.val_mAPs.append(val_map)\n",
    "    def finish(self):\n",
    "        total_time = time.time()-self.start\n",
    "        mins = int(total_time // 60)\n",
    "        secs = int(total_time % 60)\n",
    "        print(f\"Total Training Time: {mins} min {secs} sec\")\n",
    "        return total_time\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, scheduler_cos, scheduler_plateau, criterion, train_loader, val_loader, device, monitor, patience, warmup_epochs, amp_dtype, accumulation_steps):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler_cos = scheduler_cos\n",
    "        self.scheduler_plateau = scheduler_plateau\n",
    "        self.criterion = criterion\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        self.monitor = monitor\n",
    "        self.patience = patience\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.amp_dtype = amp_dtype\n",
    "        self.accumulation_steps = accumulation_steps\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.epochs_no_improve = 0\n",
    "        self.base_lr=optimizer.param_groups[0]['lr'] # store the base LR for warm‑up calculations\n",
    "        self.best_state = None\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        total_samples = 0\n",
    "        self.optimizer.zero_grad()\n",
    "        for batch_idx, (images, labels) in enumerate(self.train_loader):\n",
    "            images = images.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            with autocast(device_type=self.device.type, dtype=amp_dtype): # GPU: forward + loss w/ BF16 Automatic Mixed Precision. Default: FP32 precision\n",
    "                logits = self.model(images)\n",
    "                loss = self.criterion(logits, labels)\n",
    "                loss = loss / self.accumulation_steps\n",
    "            loss.backward()# backward pass\n",
    "            if (batch_idx + 1) % self.accumulation_steps == 0:\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "            batch_size = images.size(0)  \n",
    "            running_loss += loss.item() * batch_size * self.accumulation_steps\n",
    "            total_samples += batch_size\n",
    "        if (batch_idx + 1) % self.accumulation_steps != 0: # flush gradients if the last batch didn’t trigger a step\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        return epoch_loss\n",
    "    \n",
    "    def validate_epoch(self):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        total_samples = 0\n",
    "        all_probs = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in self.val_loader:\n",
    "                imgs = imgs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                logits = self.model(imgs)\n",
    "                loss = self.criterion(logits, labels)\n",
    "                batch_size = imgs.size(0)\n",
    "                running_loss += loss.item() * batch_size\n",
    "                total_samples += batch_size\n",
    "                probabilities = torch.sigmoid(logits)\n",
    "                all_probs.append(probabilities.cpu().numpy())\n",
    "                all_labels.append(labels.cpu().numpy())\n",
    "        val_loss = running_loss / total_samples\n",
    "        all_probs = np.vstack(all_probs)\n",
    "        all_labels = np.vstack(all_labels)\n",
    "        per_label_AP = [average_precision_score(all_labels[:, i], all_probs[:, i]) for i in range(all_labels.shape[1])]\n",
    "        val_mAP = float(np.mean(per_label_AP))\n",
    "        return val_loss, per_label_AP, val_mAP\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            # warm‑up LR for first few epochs \n",
    "            if epoch < self.warmup_epochs:\n",
    "                warmup_lr = self.base_lr * (epoch + 1) / self.warmup_epochs\n",
    "                for pg in self.optimizer.param_groups:\n",
    "                    pg['lr'] = warmup_lr\n",
    "            start = time.time()\n",
    "            train_loss = self.train_epoch()\n",
    "            val_loss, val_per_label_AP, val_mAP = self.validate_epoch()\n",
    "            total_time = time.time() - start\n",
    "            mins = int(total_time // 60)\n",
    "            secs = int(total_time % 60)\n",
    "            # Scheduler steps \n",
    "            self.scheduler_cos.step()\n",
    "            self.scheduler_plateau.step(val_loss) \n",
    "            # Print epoch summary\n",
    "            print(f\"\\nEpoch {epoch}: Train Loss={train_loss:.4f} | Val Loss={val_loss:.4f} | Val mAP={val_mAP:.4f} ({mins} min {secs} sec)\")\n",
    "            # Early stopping & per‐class AP logging\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.epochs_no_improve = 0\n",
    "                self.best_state = self.model.state_dict()\n",
    "                torch.save(self.best_state, \"best_model.pt\")\n",
    "                print(f\"New best_model.pt saved at epoch {epoch} with val loss: {val_loss:.4f}\")\n",
    "                # Print a little table of per‐class AP\n",
    "                print(\"   Validation per-class AP:\")\n",
    "                label_names = self.val_loader.dataset.label_columns\n",
    "                for name, AP in zip(label_names, val_per_label_AP):\n",
    "                    print(f\"     {name:<15s} {AP:.4f}\")\n",
    "                print(f\"   Validation mean AP: {val_mAP:.4f}\")\n",
    "            else:\n",
    "                self.epochs_no_improve += 1\n",
    "                if self.epochs_no_improve >= self.patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "            # Record in monitor\n",
    "            self.monitor.report_epoch(train_loss, val_loss, val_mAP)\n",
    "        if self.best_state is not None:\n",
    "            self.model.load_state_dict(self.best_state) # Load best weights\n",
    "        self.monitor.finish() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7353e7",
   "metadata": {},
   "source": [
    "## 5. Main Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf9feab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions saved to .csv files.\n",
      "Train samples:      162\n",
      "Validation samples: 21\n",
      "Test samples:       17\n",
      "Using num_workers: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/360deg_env/lib/python3.11/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load labels to df\n",
    "df = load_csv_to_df('miml_dataset/miml_labels_1.csv','miml_dataset/images')\n",
    "if DEBUG_MODE:\n",
    "    df = df.sample(n=200, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "nonlabel_cols = {\"external_id\", \"Filenames\", \"group_id\", \"image_path\",\"Problematic\", \"Extra Notes\", \"Revisit\"}\n",
    "label_columns = [col for col in df.columns if col not in nonlabel_cols]\n",
    "df[label_columns] = df[label_columns].fillna(0) # Fill NaN entries with 0\n",
    "# Split train/val/test partitions\n",
    "df_train_and_val, df_test = group_stratified_split(df, label_columns=label_columns, group_col=\"group_id\", split_ratio=TEST_RATIO, seed=RANDOM_SEED)\n",
    "relative_val_ratio = VAL_RATIO / (TRAIN_RATIO + VAL_RATIO)\n",
    "df_train, df_val = group_stratified_split(df_train_and_val, label_columns=label_columns, group_col=\"group_id\", split_ratio=relative_val_ratio, seed=RANDOM_SEED)\n",
    "# Save partitions to .csv\n",
    "df_train.to_csv(\"train_partition.csv\", index=False)\n",
    "df_val.to_csv(\"val_partition.csv\", index=False)\n",
    "df_test.to_csv(\"test_partition.csv\", index=False)\n",
    "print(\"Partitions saved to .csv files.\")\n",
    "# Load paritions from .csv\n",
    "df_train = pd.read_csv(\"train_partition.csv\")\n",
    "df_val   = pd.read_csv(\"val_partition.csv\")\n",
    "df_test  = pd.read_csv(\"test_partition.csv\")\n",
    "# DataLoaders\n",
    "train_dataset = DataPartition(df_train, label_columns, transform=train_transforms)\n",
    "val_dataset   = DataPartition(df_val,   label_columns, transform=val_transforms)\n",
    "test_dataset  = DataPartition(df_test,  label_columns, transform=val_transforms)\n",
    "if USE_GPU and torch.cuda.is_available(): # Set num_workers for GPU\n",
    "    optimal_num_workers = min(8, os.cpu_count() // 2)\n",
    "else:\n",
    "    optimal_num_workers = 0        \n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=optimal_num_workers, pin_memory=pin_memory)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=optimal_num_workers, pin_memory=pin_memory)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=optimal_num_workers,pin_memory=pin_memory)\n",
    "print(f\"Train samples:      {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples:       {len(test_dataset)}\")\n",
    "print(f\"Using num_workers: {optimal_num_workers}\")\n",
    "# Model, optimizer, scheduler\n",
    "model = SwinTransformerMultiLabel(num_classes=len(label_columns),pretrained=True).to(device)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.05, amsgrad=False)\n",
    "cos_scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=SCHEDULER_T0, T_mult=SCHEDULER_T_MULT, eta_min=MIN_LR)\n",
    "plateau_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, threshold=1e-4, cooldown=1, min_lr=MIN_LR)\n",
    "# Train \n",
    "monitor = TrainingMonitor()\n",
    "trainer = Trainer(model=model, \n",
    "                    optimizer=optimizer,\n",
    "                    scheduler_cos=cos_scheduler, \n",
    "                    scheduler_plateau=plateau_scheduler,\n",
    "                    criterion=loss_fn,\n",
    "                    train_loader=train_loader,\n",
    "                    val_loader=val_loader,\n",
    "                    device=device, \n",
    "                    monitor=monitor,\n",
    "                    patience=PATIENCE, \n",
    "                    warmup_epochs=3, \n",
    "                    amp_dtype=amp_dtype,\n",
    "                    accumulation_steps=2\n",
    "    )\n",
    "trainer.train(N_EPOCHS)\n",
    "# Save in Classifier wrapper w/ Prediction Threshold Settings\n",
    "def find_optimal_thresholds(model, val_loader, device, num_classes, n_steps=101):\n",
    "        model.eval()\n",
    "        all_probs = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                logits = model(images)\n",
    "                probs = torch.sigmoid(logits).cpu().numpy()\n",
    "                all_probs.append(probs)\n",
    "                all_labels.append(labels.numpy())\n",
    "        all_probs  = np.vstack(all_probs)\n",
    "        all_labels = np.vstack(all_labels)\n",
    "\n",
    "        thresholds = np.zeros(num_classes, dtype=float)\n",
    "        taus = np.linspace(0, 1, n_steps)\n",
    "        for k in range(num_classes):\n",
    "            best_f1, best_tau = 0.0, 0.5\n",
    "            for tau in taus:\n",
    "                preds_k = (all_probs[:, k] >= tau).astype(int)\n",
    "                f1 = f1_score(all_labels[:, k], preds_k, zero_division=0)\n",
    "                if f1 > best_f1:\n",
    "                    best_f1, best_tau = f1, tau\n",
    "            thresholds[k] = best_tau\n",
    "        return thresholds\n",
    "if THRESHOLD_MODE == 'per_label': # Pick Thresholds on Validation\n",
    "    thresholds = find_optimal_thresholds(model, val_loader, device, num_classes=len(label_columns), n_steps=101)\n",
    "    print(\"\\nOptimal per-class thresholds:\", thresholds)\n",
    "else: # Single Global Threshold\n",
    "    thresholds = np.full(len(label_columns), GLOBAL_THRESHOLD, dtype=float)\n",
    "print(\"Using thresholds:\", thresholds)\n",
    "classifier = Classifier(model, val_transforms, device, labels=label_columns, thresholds=thresholds)\n",
    "classifier.save('best_classifier')\n",
    "# Test set evaluation\n",
    "print(\"\\nTest Set performance:\")\n",
    "model.eval()\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        logits = model(images)\n",
    "        probabilities = torch.sigmoid(logits).cpu().numpy()\n",
    "        all_probs.append(probabilities)\n",
    "        all_labels.append(labels.numpy())\n",
    "all_probs  = np.vstack(all_probs)\n",
    "all_labels = np.vstack(all_labels)\n",
    "binary_predictions = (all_probs >= thresholds).astype(int)\n",
    "# Classification Report on Test Set\n",
    "precisions, recalls, f1s, supports = precision_recall_fscore_support(all_labels, binary_predictions, zero_division=0)\n",
    "for idx, label in enumerate(label_columns):\n",
    "    precision = precisions[idx]\n",
    "    recall = recalls[idx]\n",
    "    f1 = f1s[idx]\n",
    "    num_occurrences = supports[idx]\n",
    "    print(f\"{label:<15s} Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}, num_occurences={num_occurrences}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "360deg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
