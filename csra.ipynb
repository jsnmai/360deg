{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c49d93ef",
   "metadata": {},
   "source": [
    "# Training Pipeline Notebook\n",
    "\n",
    "This notebook bundles configuration, dataset utilities, model definitions, training loop, and evaluation into a single self‑contained workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6510c123",
   "metadata": {},
   "source": [
    "## 1. Configuration & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81465c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd            \n",
    "from pandas import json_normalize                  \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader \n",
    "from torch.amp import autocast\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from PIL import Image\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from sklearn.metrics import average_precision_score, precision_recall_fscore_support, f1_score\n",
    "from data_utils import DataPartition\n",
    "import warnings # Suppress warnings that currently do not affect execution\n",
    "warnings.filterwarnings(\"ignore\", message=\"torch.meshgrid: in an upcoming release\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Cannot set number of intraop threads after parallel work has started or after set_num_threads call\")\n",
    "\n",
    "# Hyperparameters\n",
    "DEBUG_MODE = True # Uses sample of 200 \n",
    "USE_GPU = False\n",
    "MODEL_NAME = \"swinv2_base_window12to24_192to384\"\n",
    "IMG_WIDTH = 384\n",
    "N_EPOCHS = 2          \n",
    "BATCH_SIZE = 2\n",
    "LEARNING_RATE = 1e-5\n",
    "PATIENCE = 8\n",
    "DROPOUT_RATE = 0.5\n",
    "SCHEDULER_T0 = 6\n",
    "SCHEDULER_T_MULT = 1\n",
    "MIN_LR = 1e-6\n",
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "RANDOM_SEED = 42\n",
    "THRESHOLD_MODE = 'per_label'  # choices: 'per_label', 'global'\n",
    "GLOBAL_THRESHOLD = 0.5\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Device setup\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    optimal_num_workers = min(8, os.cpu_count() // 2)\n",
    "    pin_memory = True\n",
    "    amp_dtype = torch.bfloat16\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    optimal_num_workers = 0 \n",
    "    pin_memory = False\n",
    "    amp_dtype = torch.float32\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06279773",
   "metadata": {},
   "source": [
    "## 2. Dataset Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81e17b5",
   "metadata": {},
   "source": [
    "### For NDJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e705c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NDJSON_PATH = 'demo_360.ndjson'\n",
    "IMG_DIR = \"miml_dataset/images\"  \n",
    "\n",
    "max_count = 0\n",
    "deepest_order = None\n",
    "with open(NDJSON_PATH, \"r\") as file:\n",
    "    for line in file:\n",
    "        record = json.loads(line)\n",
    "        found_columns = []\n",
    "        for project in record.get(\"projects\", {}).values():\n",
    "            for label in project.get(\"labels\", []):\n",
    "                for cls in label.get(\"annotations\", {}).get(\"classifications\", []):\n",
    "                    found_columns.append(cls[\"name\"])\n",
    "        if len(found_columns) > max_count:\n",
    "            max_count = len(found_columns)\n",
    "            deepest_order = found_columns\n",
    "print(\"Deepest order of classifications/labels:\", deepest_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a835d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream the NDJSON and build one dict per image\n",
    "records = []\n",
    "distance_columns = set()\n",
    "with open(NDJSON_PATH, \"r\") as file:\n",
    "    for line in file:\n",
    "        record = json.loads(line)\n",
    "        ext_id = record[\"data_row\"][\"external_id\"]\n",
    "        # initialize the row with external_id + all label cols set to NaN\n",
    "        row = {\"external_id\": ext_id} \n",
    "        for label in deepest_order:\n",
    "            row[label] = np.nan\n",
    "        # fill in each classification\n",
    "        for project in record.get(\"projects\", {}).values():\n",
    "            for label in project.get(\"labels\", []):\n",
    "                for cls in label[\"annotations\"].get(\"classifications\", []):\n",
    "                    name = cls.get(\"name\")\n",
    "                    if name not in deepest_order:\n",
    "                        continue\n",
    "                    # Case: Free‑text fields (Extra Notes)\n",
    "                    if cls.get(\"text_answer\"):\n",
    "                        row[name] = cls[\"text_answer\"].get(\"content\")\n",
    "                    # Case: Checklist fields (confidence score and distance)\n",
    "                    elif cls.get(\"checklist_answers\"):\n",
    "                        answers = [a.get(\"name\") for a in cls[\"checklist_answers\"]]\n",
    "                        # extract the numeric (confidence) answer\n",
    "                        conf = next((a for a in answers if a and a[0].isdigit()), None)\n",
    "                        # extract the non‑numeric (distance) answer\n",
    "                        dist = next((a for a in answers if not (a and a[0].isdigit())), None)\n",
    "\n",
    "                        row[name] = conf\n",
    "                        # create the distance column on the fly\n",
    "                        distance_col = str(name)+\"_distance\"\n",
    "                        distance_columns.add(distance_col)\n",
    "                        row[distance_col] = dist\n",
    "                    # Case: Radio fields (Lily, Problematic, Revisit)\n",
    "                    elif cls.get(\"radio_answer\"):\n",
    "                        row[name] = cls[\"radio_answer\"].get(\"name\")\n",
    "                    # Fallback: raw value string\n",
    "                    else:\n",
    "                        row[name] = cls.get(\"value\")\n",
    "        records.append(row)\n",
    "df_all = pd.DataFrame(records) # Build the DataFrame (pandas will union in any distance cols)\n",
    "nonlabel_columns = {\"external_id\", \"Problematic\", \"Extra Notes\", \"Revisit\"}\n",
    "nonlabel_columns.update(distance_columns)\n",
    "label_columns = [col for col in df_all.columns if col not in nonlabel_columns]\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb4b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re‑order columns by adding labels w/ its corresponding *_distance column(if it exists) in the order as it appears in LabelBox(deepest_order)\n",
    "ordered_columns = [\"external_id\"]\n",
    "for label in deepest_order:\n",
    "    ordered_columns.append(label)\n",
    "    distance_col = str(label)+\"_distance\"\n",
    "    if distance_col in df_all.columns: # Also add corresponding *_distance column if it exists\n",
    "        ordered_columns.append(distance_col)\n",
    "df_all = df_all[ordered_columns]\n",
    "df_all.head()\n",
    "\n",
    "# ordered = (\n",
    "#     [\"external_id\"] +\n",
    "#     label_columns +\n",
    "#     distance_cols \n",
    "# )\n",
    "# df_all = df_all[ordered]\n",
    "# df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec112d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img_path_mapping(root_img_dir):\n",
    "    \"\"\"\n",
    "    Recursively scans the root image directory for JPEG images in any \"split_jpg\" folder\n",
    "    and creates a mapping from each image's basename to its full local file path.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Mapping { img_filename : img_path }.\n",
    "    \"\"\"\n",
    "    glob_pattern = os.path.join(root_img_dir, \"*\", \"*\", \"split_jpg\", \"*.jpg\")\n",
    "    img_paths = glob.glob(glob_pattern, recursive=True)\n",
    "    mapping = {}\n",
    "    for img_path in img_paths:\n",
    "        img_filename = os.path.basename(img_path)\n",
    "        mapping[img_filename] = img_path\n",
    "    return mapping\n",
    "\n",
    "def get_base_filename(filename):\n",
    "    '''\n",
    "    Strip off suffixes like \"_left.jpg\", \"_right.jpg\" or just drop the extension\n",
    "    '''\n",
    "    for suffix in [\"_left.jpg\", \"_right.jpg\"]:\n",
    "        if filename.endswith(suffix):\n",
    "            return filename[:-len(suffix)] # Remove specified suffix\n",
    "    return os.path.splitext(filename)[0] # Fallback: Removes extensions\n",
    "\n",
    "path_map = create_img_path_mapping(IMG_DIR) # Build the mapping from filename to full path  \n",
    "group_id_series= df_all[\"external_id\"].apply(get_base_filename) # Create group_id column\n",
    "img_path_series = df_all[\"external_id\"].map(path_map) # Create image_path column\n",
    "df_all.insert(0, \"group_id\", group_id_series) # Add group_id and image_path\n",
    "df_all.insert(1, \"image_path\", img_path_series) # Add image_path\n",
    "df_all = df_all.drop(columns=nonlabel_columns) # Drop \n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6448d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary = df_all.copy().fillna(0) # Make a binary copy with NaN turned to 0s\n",
    "df_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6513e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_THRESHOLD = 3\n",
    "\n",
    "def to_binary(entry): \n",
    "    num = int(str(entry).split()[0])  # parse out a leading integer\n",
    "    return int((num > 0) and int(num <= POSITIVE_THRESHOLD))\n",
    "\n",
    "for col in label_columns:\n",
    "    df_binary[col] = df_binary[col].apply(to_binary)\n",
    "df_binary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f618160",
   "metadata": {},
   "source": [
    "### For CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee06424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Parsers and Helpers\n",
    "def load_csv_to_df(filepath, img_dir):\n",
    "    df = pd.read_csv(filepath) \n",
    "    df[\"group_id\"] = [os.path.splitext(filename)[0] for filename in df[\"Filenames\"]] # Add 'group_id' by removing the file extension.\n",
    "    df[\"image_path\"] = [os.path.normpath(os.path.join(img_dir, filename)) for filename in df[\"Filenames\"]] # Add 'image_path' by joining the img_dir with the filename.\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139dcd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST move DataPartition into a separate file (data_utils.py)\n",
    "# in order to run the notebook version with num_workers > 0 for GPU training\n",
    "'''\n",
    "class DataPartition(Dataset):\n",
    "    def __init__(self, df, label_columns, transform=None):\n",
    "        self.label_columns = label_columns\n",
    "        self.transform = transform\n",
    "        self.img_paths = df[\"image_path\"].tolist() # List of image paths\n",
    "        self.labels = df[label_columns].to_numpy(dtype=np.float32) # 2-D Array of of shape (N_samples, N_labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path  = self.img_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\") # Retrieve image\n",
    "        if self.transform:                        # Apply transformations to image\n",
    "            img = self.transform(img)\n",
    "        label_vector = torch.from_numpy(self.labels[idx]) # Retrieve label vector for the given sample\n",
    "        return img, label_vector\n",
    "'''\n",
    "        \n",
    "# Data Augmentation (Transforms)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_WIDTH, IMG_WIDTH)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # 50% chance to flip horizontally\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(3)], p=0.2),\n",
    "    transforms.RandomApply([transforms.RandomAffine(       # Randomly apply\n",
    "                            degrees=10,                    # small rotation: rotate within [-10, 10] degrees\n",
    "                            translate=(0.05, 0.05),        # small translation: shift up to 5% of the image dimensions\n",
    "                            scale=(0.95, 1.05))], p=0.5),  # slightly zoom in or out\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_WIDTH, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "def group_stratified_split(df, label_columns, group_col, split_ratio, seed):\n",
    "    unique_groups_array = df[group_col].unique()\n",
    "    aggregated_labels_list = [] \n",
    "    for group in unique_groups_array:\n",
    "        group_df = df[df[group_col] == group] # Extract the subset of rows for this group.\n",
    "        series_max = group_df[label_columns].max() # Use max() across rows for each label column to simulate a logical OR combining the labels per group to a panda Series\n",
    "        agg_labels = series_max.values # convert to numpy 1D array\n",
    "        aggregated_labels_list.append(agg_labels)\n",
    "    aggregated_labels_array = np.vstack(aggregated_labels_list) # stack into shape (n_groups, n_labels)\n",
    "    # Initialize the multilabel stratified shuffle split with the desired test size and random seed.\n",
    "    splitter = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=split_ratio, random_state=seed)\n",
    "    # Use the splitter to get indices for train and test groups based on the aggregated labels.\n",
    "    for first_split_idx, second_split_idx in splitter.split(unique_groups_array.reshape(-1, 1), aggregated_labels_array):\n",
    "        first_groups = unique_groups_array[first_split_idx]\n",
    "        second_groups = unique_groups_array[second_split_idx]\n",
    "    # Create the final DataFrame splits by selecting rows that belong to each group split.\n",
    "    df_split_1 = df[df[group_col].isin(first_groups)].reset_index(drop=True)\n",
    "    df_split_2 = df[df[group_col].isin(second_groups)].reset_index(drop=True)\n",
    "    return df_split_1, df_split_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f87a7",
   "metadata": {},
   "source": [
    "## 3. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb0564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSRA(nn.Module): # one basic block \n",
    "    def __init__(self, input_dim, num_classes, T, lam):\n",
    "        super(CSRA, self).__init__()\n",
    "        self.T = T      # temperature       \n",
    "        self.lam = lam  # Lambda                        \n",
    "        self.head = nn.Conv2d(input_dim, num_classes, 1, bias=False)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (B d H W)\n",
    "        # normalize classifier\n",
    "        # score (B C HxW)\n",
    "        score = self.head(x) / torch.norm(self.head.weight, dim=1, keepdim=True).transpose(0,1)\n",
    "        score = score.flatten(2)\n",
    "        base_logit = torch.mean(score, dim=2)\n",
    "\n",
    "        if self.T == 99: # max-pooling\n",
    "            att_logit = torch.max(score, dim=2)[0]\n",
    "        else:\n",
    "            score_soft = self.softmax(score * self.T)\n",
    "            att_logit = torch.sum(score * score_soft, dim=2)\n",
    "\n",
    "        return base_logit + self.lam * att_logit\n",
    "\n",
    "class MHA(nn.Module):  # multi-head attention\n",
    "    temp_settings = {  # softmax temperature settings\n",
    "        1: [1],\n",
    "        2: [1, 99],\n",
    "        4: [1, 2, 4, 99],\n",
    "        6: [1, 2, 3, 4, 5, 99],\n",
    "        8: [1, 2, 3, 4, 5, 6, 7, 99]\n",
    "    }\n",
    "\n",
    "    def __init__(self, num_heads, lam, input_dim, num_classes):\n",
    "        super(MHA, self).__init__()\n",
    "        self.temp_list = self.temp_settings[num_heads]\n",
    "        self.multi_head = nn.ModuleList([\n",
    "            CSRA(input_dim, num_classes, self.temp_list[i], lam)\n",
    "            for i in range(num_heads)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        logit = 0.\n",
    "        for head in self.multi_head:\n",
    "            logit += head(x)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customModel(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=True):\n",
    "        super().__init__()\n",
    "        # 1) Model backbone without pooling/head\n",
    "        self.model = timm.create_model(\n",
    "            MODEL_NAME, \n",
    "            pretrained=pretrained, \n",
    "            num_classes=0, # out_features, strip of model head/classifier\n",
    "            global_pool=\"\") # no pooling\n",
    "        # 2) pooling + dropout + classifier head\n",
    "        in_features = self.model.num_features\n",
    "        self.dropout = nn.Dropout(DROPOUT_RATE)\n",
    "        # replace head with MHA\n",
    "        self.att = MHA(num_heads=4, lam=0.2, input_dim=in_features, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        fmap = self.model.forward_features(imgs) # Backbone -> feature map [B, H', W', C], downsampled\n",
    "        fmap = fmap.permute(0, 3, 1, 2) # Permute to [B, C, H', W']\n",
    "        fmap = self.dropout(fmap)\n",
    "        output = self.att(fmap)   \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab75cd4",
   "metadata": {},
   "source": [
    "## 4. Training Monitor & Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983df83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingMonitor:\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_mAPs = []\n",
    "        self.start=time.time()\n",
    "    def report_epoch(self, train_loss, val_loss, val_map):\n",
    "        self.train_losses.append(train_loss)\n",
    "        self.val_losses.append(val_loss)\n",
    "        self.val_mAPs.append(val_map)\n",
    "    def finish(self):\n",
    "        total_time = time.time()-self.start\n",
    "        mins = int(total_time // 60)\n",
    "        secs = int(total_time % 60)\n",
    "        print(f\"Total Training Time: {mins} min {secs} sec\")\n",
    "        return total_time\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, scheduler_cos, scheduler_plateau, criterion, train_loader, val_loader, device, monitor, patience, warmup_epochs, amp_dtype, accumulation_steps):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler_cos = scheduler_cos\n",
    "        self.scheduler_plateau = scheduler_plateau\n",
    "        self.criterion = criterion\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        self.monitor = monitor\n",
    "        self.patience = patience\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.amp_dtype = amp_dtype\n",
    "        self.accumulation_steps = accumulation_steps\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.epochs_no_improve = 0\n",
    "        self.base_lr=optimizer.param_groups[0]['lr'] # store the base LR for warm‑up calculations\n",
    "        self.best_state = None\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        total_samples = 0\n",
    "        self.optimizer.zero_grad()\n",
    "        for batch_idx, (images, labels) in enumerate(self.train_loader):\n",
    "            images = images.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            with autocast(device_type=self.device.type, dtype=self.amp_dtype): # GPU: forward + loss w/ BF16 Automatic Mixed Precision. Default: FP32 precision\n",
    "                logits = self.model(images)\n",
    "                loss = self.criterion(logits, labels)\n",
    "                loss = loss / self.accumulation_steps\n",
    "            loss.backward()# backward pass\n",
    "            if (batch_idx + 1) % self.accumulation_steps == 0:\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "            batch_size = images.size(0)  \n",
    "            running_loss += loss.item() * batch_size * self.accumulation_steps\n",
    "            total_samples += batch_size\n",
    "        if (batch_idx + 1) % self.accumulation_steps != 0: # flush gradients if the last batch didn’t trigger a step\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        return epoch_loss\n",
    "    \n",
    "    def validate_epoch(self):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        total_samples = 0\n",
    "        all_probs = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in self.val_loader:\n",
    "                imgs = imgs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                logits = self.model(imgs)\n",
    "                loss = self.criterion(logits, labels)\n",
    "                batch_size = imgs.size(0)\n",
    "                running_loss += loss.item() * batch_size\n",
    "                total_samples += batch_size\n",
    "                probabilities = torch.sigmoid(logits)\n",
    "                all_probs.append(probabilities.cpu().numpy())\n",
    "                all_labels.append(labels.cpu().numpy())\n",
    "        val_loss = running_loss / total_samples\n",
    "        all_probs = np.vstack(all_probs)\n",
    "        all_labels = np.vstack(all_labels)\n",
    "        per_label_AP = [average_precision_score(all_labels[:, i], all_probs[:, i]) for i in range(all_labels.shape[1])]\n",
    "        val_mAP = float(np.mean(per_label_AP))\n",
    "        return val_loss, per_label_AP, val_mAP\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            # warm‑up LR for first few epochs \n",
    "            if epoch < self.warmup_epochs:\n",
    "                warmup_lr = self.base_lr * (epoch + 1) / self.warmup_epochs\n",
    "                for pg in self.optimizer.param_groups:\n",
    "                    pg['lr'] = warmup_lr\n",
    "            start = time.time()\n",
    "            train_loss = self.train_epoch()\n",
    "            val_loss, val_per_label_AP, val_mAP = self.validate_epoch()\n",
    "            total_time = time.time() - start\n",
    "            mins = int(total_time // 60)\n",
    "            secs = int(total_time % 60)\n",
    "            # Scheduler steps \n",
    "            self.scheduler_cos.step()\n",
    "            self.scheduler_plateau.step(val_loss) \n",
    "            # Print epoch summary\n",
    "            print(f\"\\nEpoch {epoch}: Train Loss={train_loss:.4f} | Val Loss={val_loss:.4f} | Val mAP={val_mAP:.4f} ({mins} min {secs} sec)\")\n",
    "            # Early stopping & per‐class AP logging\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.epochs_no_improve = 0\n",
    "                self.best_state = self.model.state_dict()\n",
    "                torch.save(self.best_state, \"best_model.pt\")\n",
    "                print(f\"New best_model.pt saved at epoch {epoch} with val loss: {val_loss:.4f}\")\n",
    "                # Print a little table of per‐class AP\n",
    "                print(\"   Validation per-class AP:\")\n",
    "                label_names = self.val_loader.dataset.label_columns\n",
    "                for name, AP in zip(label_names, val_per_label_AP):\n",
    "                    print(f\"     {name:<15s} {AP:.4f}\")\n",
    "                print(f\"   Validation mean AP: {val_mAP:.4f}\")\n",
    "            else:\n",
    "                self.epochs_no_improve += 1\n",
    "                if self.epochs_no_improve >= self.patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "            # Record in monitor\n",
    "            self.monitor.report_epoch(train_loss, val_loss, val_mAP)\n",
    "        if self.best_state is not None:\n",
    "            self.model.load_state_dict(self.best_state) # Load best weights\n",
    "        self.monitor.finish() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78e866b",
   "metadata": {},
   "source": [
    "## 5. Classifier Wrapper & Prediction Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e7f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, model, transform, device, labels, thresholds):\n",
    "        self.model = model.to(device).eval()\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "        self.labels = labels \n",
    "        self.thresholds = thresholds\n",
    "\n",
    "    def predict_probability(self, img):\n",
    "        tensor = self.transform(img).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(tensor)\n",
    "            return torch.sigmoid(logits).cpu().numpy()[0]\n",
    "\n",
    "    def predict_binary(self, img):\n",
    "        probabilities = self.predict_probability(img)\n",
    "        return (probabilities >= self.thresholds).astype(int)\n",
    "\n",
    "    def save(self, base_filename):\n",
    "        torch.save(self.model.state_dict(), base_filename + \".pt\") # Save model weights\n",
    "        thresholds_list = self.thresholds.tolist() # Gather thresholds into a JSON‑safe list\n",
    "        config = { # Build and write the JSON metadata config\n",
    "            \"thresholds\": thresholds_list,\n",
    "            \"labels\": self.labels\n",
    "        }\n",
    "        with open(base_filename + \".json\", \"w\") as file:\n",
    "            json.dump(config, file, indent=2)\n",
    "        print(f\"Model Weights saved as {base_filename}.pt | Classifier Metadata saved as {base_filename}.json\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load(config_filename, transform, device):\n",
    "        config = json.load(open(config_filename, \"r\"))\n",
    "        labels = config[\"labels\"]\n",
    "        thresholds = np.array(config[\"thresholds\"], dtype=float)\n",
    "        state_dict_filename = config_filename.replace(\".json\", \".pt\") # Extract weights file name\n",
    "        # rebuild and load model\n",
    "        model = customModel(num_classes=len(labels), pretrained=False)\n",
    "        state = torch.load(state_dict_filename, map_location=device)\n",
    "        model.load_state_dict(state)\n",
    "        model.to(device).eval()\n",
    "        return Classifier(model=model, transform=transform, device=device, labels=labels,thresholds=thresholds)\n",
    "\n",
    "def find_optimal_thresholds(model, val_loader, device, num_classes, n_steps=101):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            logits = model(images)\n",
    "            probabilities = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_probs.append(probabilities)\n",
    "            all_labels.append(labels.numpy())\n",
    "    all_probs  = np.vstack(all_probs)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    thresholds = np.zeros(num_classes, dtype=float)\n",
    "    taus = np.linspace(0, 1, n_steps)\n",
    "    for k in range(num_classes):\n",
    "        best_f1, best_tau = 0.0, 0.5\n",
    "        for tau in taus:\n",
    "            preds_k = (all_probs[:, k] >= tau).astype(int)\n",
    "            f1 = f1_score(all_labels[:, k], preds_k, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_tau = f1, tau\n",
    "        thresholds[k] = best_tau\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7353e7",
   "metadata": {},
   "source": [
    "## 6. Main Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf9feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels to df\n",
    "IMG_DIR = 'miml_dataset/images'\n",
    "LABELS_PATH = 'miml_dataset/miml_labels_1.csv'\n",
    "df = load_csv_to_df(LABELS_PATH,IMG_DIR)\n",
    "if DEBUG_MODE:\n",
    "    df = df.sample(n=200, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "nonlabel_cols = {\"external_id\", \"Filenames\", \"group_id\", \"image_path\", \"Problematic\", \"Extra Notes\", \"Revisit\"}\n",
    "label_columns = [col for col in df.columns if col not in nonlabel_cols and not col.endswith(\"_distance\")]\n",
    "df[label_columns] = df[label_columns].fillna(0) # Fill NaN entries with 0\n",
    "\n",
    "# Split train/val/test partitions & save to .csv\n",
    "df_train_and_val, df_test = group_stratified_split(df, label_columns=label_columns, group_col=\"group_id\", split_ratio=TEST_RATIO, seed=RANDOM_SEED)\n",
    "relative_val_ratio = VAL_RATIO / (TRAIN_RATIO + VAL_RATIO)\n",
    "df_train, df_val = group_stratified_split(df_train_and_val, label_columns=label_columns, group_col=\"group_id\", split_ratio=relative_val_ratio, seed=RANDOM_SEED)\n",
    "df_train.to_csv(\"train_partition.csv\", index=False)\n",
    "df_val.to_csv(\"val_partition.csv\", index=False)\n",
    "df_test.to_csv(\"test_partition.csv\", index=False)\n",
    "print(\"Partitions saved to .csv files.\")\n",
    "# Load partitions from .csv\n",
    "df_train = pd.read_csv(\"train_partition.csv\")\n",
    "df_val   = pd.read_csv(\"val_partition.csv\")\n",
    "df_test  = pd.read_csv(\"test_partition.csv\")\n",
    "print(\"Partitions loaded from .csv files.\")\n",
    "# DataLoaders\n",
    "train_dataset = DataPartition(df_train, label_columns, transform=train_transforms)\n",
    "val_dataset   = DataPartition(df_val,   label_columns, transform=val_transforms)\n",
    "test_dataset  = DataPartition(df_test,  label_columns, transform=val_transforms)    \n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=optimal_num_workers, pin_memory=pin_memory)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=optimal_num_workers, pin_memory=pin_memory)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=optimal_num_workers, pin_memory=pin_memory)\n",
    "print(f\"Train samples:      {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples:       {len(test_dataset)}\")\n",
    "print(f\"Using num_workers: {optimal_num_workers}\")\n",
    "# Model, optimizer, scheduler\n",
    "model = customModel(num_classes=len(label_columns),pretrained=True).to(device)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.05, amsgrad=False)\n",
    "cos_scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=SCHEDULER_T0, T_mult=SCHEDULER_T_MULT, eta_min=MIN_LR)\n",
    "plateau_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, threshold=1e-4, cooldown=1, min_lr=MIN_LR)\n",
    "# Train \n",
    "monitor = TrainingMonitor()\n",
    "trainer = Trainer(model=model, \n",
    "                    optimizer=optimizer,\n",
    "                    scheduler_cos=cos_scheduler, \n",
    "                    scheduler_plateau=plateau_scheduler,\n",
    "                    criterion=loss_fn,\n",
    "                    train_loader=train_loader,\n",
    "                    val_loader=val_loader,\n",
    "                    device=device, \n",
    "                    monitor=monitor,\n",
    "                    patience=PATIENCE, \n",
    "                    warmup_epochs=3, \n",
    "                    amp_dtype=amp_dtype,\n",
    "                    accumulation_steps=2\n",
    "    )\n",
    "trainer.train(N_EPOCHS)\n",
    "# Pick Thresholds for Predictions \n",
    "if THRESHOLD_MODE == 'per_label':\n",
    "    thresholds = find_optimal_thresholds(model, val_loader, device, num_classes=len(label_columns), n_steps=101) # on Validation\n",
    "    print(\"\\nOptimal per-class thresholds:\", thresholds)\n",
    "else: # Single Global Threshold\n",
    "    thresholds = np.full(len(label_columns), GLOBAL_THRESHOLD, dtype=float)\n",
    "print(\"Using thresholds:\", thresholds)\n",
    "# Save in Classifier wrapper\n",
    "classifier = Classifier(model, val_transforms, device, labels=label_columns, thresholds=thresholds)\n",
    "classifier.save('best_classifier')\n",
    "\n",
    "# Test set evaluation\n",
    "print(\"\\nTest Set performance:\")\n",
    "model.eval()\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        logits = model(images)\n",
    "        probabilities = torch.sigmoid(logits).cpu().numpy()\n",
    "        all_probs.append(probabilities)\n",
    "        all_labels.append(labels.numpy())\n",
    "all_probs  = np.vstack(all_probs)\n",
    "all_labels = np.vstack(all_labels)\n",
    "binary_predictions = (all_probs >= thresholds).astype(int)\n",
    "# Classification Report on Test Set\n",
    "per_class_AP = [average_precision_score(all_labels[:, i], all_probs[:, i]) for i in range(all_labels.shape[1])]\n",
    "mean_AP = float(np.mean(per_class_AP))\n",
    "precisions, recalls, f1s, supports = precision_recall_fscore_support(all_labels, binary_predictions, zero_division=0)\n",
    "for idx, label in enumerate(label_columns):\n",
    "    precision = precisions[idx]\n",
    "    recall = recalls[idx]\n",
    "    f1 = f1s[idx]\n",
    "    num_occurrences = supports[idx]\n",
    "    print(f\"{label:<15s} AP={per_class_AP[idx]:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}, num_occurences={num_occurrences}\")\n",
    "print(f\"Test Set mean AP: {mean_AP:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7fde72",
   "metadata": {},
   "source": [
    "## Single Prediction Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier.load(config_filename=\"best_classifier.json\", transform=val_transforms, device=device)\n",
    "image_path = \"miml_dataset\\\\images\\\\1291.jpg\"\n",
    "img = Image.open(image_path).convert(\"RGB\")\n",
    "probabilities = classifier.predict_probability(img)\n",
    "predictions   = classifier.predict_binary(img)\n",
    "labels = classifier.labels\n",
    "thresholds = classifier.thresholds\n",
    "# Lookup ground-truth vector in df_test\n",
    "row = df_test[df_test[\"image_path\"] == image_path].iloc[0]\n",
    "truth_vector = row[label_columns].astype(int).to_numpy()\n",
    "print(\"Labels:        \", labels)\n",
    "print(\"Thresholds:    \",\"[{}]\".format(\", \".join(f\"{t:.3f}\" for t in thresholds)))\n",
    "print(\"Probabilities: \",\"[{}]\".format(\", \".join(f\"{p:.3f}\" for p in probabilities)))\n",
    "print(\"Predictions:   \", predictions.tolist())\n",
    "print(\"GroundTruth:   \", truth_vector.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "360deg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
